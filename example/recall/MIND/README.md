# Mind

```sh
Model: "model"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
user_id (InputLayer)            [(None, 1)]          0                                            
__________________________________________________________________________________________________
gender (InputLayer)             [(None, 1)]          0                                            
__________________________________________________________________________________________________
age (InputLayer)                [(None, 1)]          0                                            
__________________________________________________________________________________________________
occupation (InputLayer)         [(None, 1)]          0                                            
__________________________________________________________________________________________________
zip (InputLayer)                [(None, 1)]          0                                            
__________________________________________________________________________________________________
movie_id (InputLayer)           [(None, 1)]          0                                            
__________________________________________________________________________________________________
sparse_emb_user_id (Embedding)  (None, 1, 16)        64          user_id[0][0]                    
__________________________________________________________________________________________________
sparse_emb_gender (Embedding)   (None, 1, 16)        48          gender[0][0]                     
__________________________________________________________________________________________________
sparse_emb_age (Embedding)      (None, 1, 16)        64          age[0][0]                        
__________________________________________________________________________________________________
sparse_emb_occupation (Embeddin (None, 1, 16)        64          occupation[0][0]                 
__________________________________________________________________________________________________
sparse_emb_zip (Embedding)      (None, 1, 16)        64          zip[0][0]                        
__________________________________________________________________________________________________
embedding_index (EmbeddingIndex (209,)               0           movie_id[0][0]                   
__________________________________________________________________________________________________
no_mask_2 (NoMask)              (None, 1, 16)        0           sparse_emb_user_id[0][0]         
                                                                 sparse_emb_gender[0][0]          
                                                                 sparse_emb_age[0][0]             
                                                                 sparse_emb_occupation[0][0]      
                                                                 sparse_emb_zip[0][0]             
__________________________________________________________________________________________________
hist_movie_id (InputLayer)      [(None, 50)]         0                                            
__________________________________________________________________________________________________
sparse_seq_emb_hist_movie_id (E multiple             3344        movie_id[0][0]                   
                                                                 hist_movie_id[0][0]              
                                                                 embedding_index[0][0]            
__________________________________________________________________________________________________
concatenate (Concatenate)       (None, 1, 80)        0           no_mask_2[0][0]                  
                                                                 no_mask_2[1][0]                  
                                                                 no_mask_2[2][0]                  
                                                                 no_mask_2[3][0]                  
                                                                 no_mask_2[4][0]                  
__________________________________________________________________________________________________
flatten (Flatten)               (None, 80)           0           concatenate[0][0]                
__________________________________________________________________________________________________
no_mask (NoMask)                [(None, 50, 16)]     0           sparse_seq_emb_hist_movie_id[1][0
__________________________________________________________________________________________________
lambda (Lambda)                 (None, 2, 80)        0           flatten[0][0]                    
__________________________________________________________________________________________________
pooling_layer (PoolingLayer)    (None, 50, 16)       0           no_mask[0][0]                    
__________________________________________________________________________________________________
hist_len (InputLayer)           [(None, 1)]          0                                            
__________________________________________________________________________________________________
no_mask_3 (NoMask)              (None, 2, 80)        0           lambda[0][0]                     
__________________________________________________________________________________________________
capsule_layer (CapsuleLayer)    (None, 2, 16)        356         pooling_layer[0][0]              
                                                                 hist_len[0][0]                   
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 2, 96)        0           no_mask_3[0][0]                  
                                                                 capsule_layer[0][0]              
__________________________________________________________________________________________________
no_mask_1 (NoMask)              [(None, 1, 16)]      0           sparse_seq_emb_hist_movie_id[0][0
__________________________________________________________________________________________________
no_mask_4 (NoMask)              (209, 16)            0           sparse_seq_emb_hist_movie_id[2][0
__________________________________________________________________________________________________
user_embedding (DNN)            (None, 2, 16)        7248        concatenate_1[0][0]              
__________________________________________________________________________________________________
pooling_layer_1 (PoolingLayer)  (None, 1, 16)        0           no_mask_1[0][0]                  
__________________________________________________________________________________________________
pooling_layer_2 (PoolingLayer)  (209, 16)            0           no_mask_4[0][0]                  
__________________________________________________________________________________________________
label_aware_attention (LabelAwa (None, 16)           0           user_embedding[0][0]             
                                                                 pooling_layer_1[0][0]            
__________________________________________________________________________________________________
sampled_softmax_layer (SampledS (None, 1)            209         pooling_layer_2[0][0]            
                                                                 label_aware_attention[0][0]      
                                                                 movie_id[0][0]                   
==================================================================================================
Total params: 11,461
Trainable params: 11,152
Non-trainable params: 309
__________________________________________________________________________________________________
```







### 实战演练

**Capsule Layer 设计**

**论文中的描述：**先给每个用户动态的计算出用户的k条兴趣（k_user），然后Capsule Layer层 直接输出用户的k条兴趣（k_user）；

**在实践中：**先给每个用户固定输出k_max条兴趣，然后在Label-aware Attention层再做自适应选取k_user条兴趣向量。【PS：在实际serving一般都是固定的k_max条兴趣】



**Label-aware Attention 设计**

在训练阶段，要进行预测的 Label 只有一个Embedding，而用户有k个Embedding，没法直接求内积计算匹配度。这里MIND提出了Label-aware Attention，思路跟DIN是一致的，就是根据 Label 的 Embedding 对用户的k个Embedding分别求出权重(所谓label-aware)，然后对用户的k个Embedding求加权和，得到最终的一个用户 Embedding。

#### 数据处理

`data.py`

正采样、负采样、数据合并



#### 模型训练

`train_mind.py`



`tf.keras.callback.EarlyStopping`

当模型训练次数epoch设置到100甚至更大时，如果模型的效果没有进一步提升，那么训练可以提前停止，继续训练很可能会导致训练过拟合，而**EarlyStopping**就是用来提前结束训练的。

| **参数**             | **描述**                                                     |
| -------------------- | ------------------------------------------------------------ |
| monitor              | 被监测的数据。                                               |
| min_delta            | 在被监测的数据中被认为是提升的最小变化， 例如，小于 min_delta 的绝对变化会被认为没有提升。 |
| patience             | 没有进步的训练轮数，在这之后训练就会被停止。                 |
| verbose              | 详细信息模式。                                               |
| mode                 | {auto, min, max} 其中之一。 在 min 模式中， 当被监测的数据停止下降，训练就会停止；在 max 模式中，当被监测的数据停止上升，训练就会停止；在 auto 模式中，方向会自动从被监测的数据的名字中判断出来。 |
| baseline             | 要监控的数量的基准值。 如果模型没有显示基准的改善，训练将停止。 |
| restore_best_weights | 是否从具有监测数量的最佳值的时期恢复模型权重。 如果为 False，则使用在训练的最后一步获得的模型权重。 |



#### 模型预测